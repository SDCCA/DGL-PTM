{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl_ptm\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dgl_ptm.PovertyTrapModel(model_identifier='trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_model_parameters(default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write parameters to config file:\n",
    "# Note that torch tensor of written to yaml file creates a binary string.\n",
    "# For creating this config file, tensors were converted to lists in initialize_model\n",
    "# A SAMPLE CONFIG FILE IS AVAILABLE AT: dgl_ptm/dgl_ptm/config.yaml\n",
    "\n",
    "import yaml\n",
    "with open('../dgl_ptm/dgl_ptm/config.yaml', 'w') as outfile:\n",
    "    yaml.dump(model.__dict__, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parameter config file and set model parameters externally:\n",
    "\n",
    "import yaml\n",
    "with open('../dgl_ptm/dgl_ptm/config.yaml', 'r') as readfile:\n",
    "    try:\n",
    "        model.__dict__ = yaml.safe_load(readfile)\n",
    "    except yaml.YAMLError as exc:\n",
    "        raise SyntaxError(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modelpar in modelpars:\n",
    "    if modelpar not in ['_model_identifier','model_graph']:\n",
    "    #     model.__dict__[modelpar] = a[modelpar]\n",
    "        if type(model.__dict__[modelpar]) is list:\n",
    "            model.__dict__[modelpar] = torch.tensor(model.__dict__[modelpar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha_dist': {'decimals': None,\n",
       "  'parameters': [1.08, 0.074],\n",
       "  'round': False,\n",
       "  'type': 'normal'},\n",
       " 'capital_dist': {'decimals': None,\n",
       "  'parameters': [0.1, 10.0],\n",
       "  'round': False,\n",
       "  'type': 'uniform'},\n",
       " 'cost_vals': tensor([0.0000, 0.4500]),\n",
       " 'gamma_vals': tensor([0.3000, 0.4500]),\n",
       " 'initial_graph_type': 'barabasi-albert',\n",
       " 'lam_dist': {'decimals': 1,\n",
       "  'parameters': [0.1, 0.9],\n",
       "  'round': True,\n",
       "  'type': 'uniform'},\n",
       " 'number_agents': 1000,\n",
       " 'sigma': 0.5,\n",
       " 'steering_parameters': {'del_prob': 0.05,\n",
       "  'edata': ['all'],\n",
       "  'epath': './edge_data',\n",
       "  'mode': 'xarray',\n",
       "  'ndata': ['all'],\n",
       "  'npath': './agent_data.zarr',\n",
       "  'ratio': 0.1,\n",
       "  'wealth_method': 'weighted_transfer',\n",
       "  'weight_a': 0.69,\n",
       "  'weight_b': 35},\n",
       " 'step_count': 0,\n",
       " 'step_target': 20,\n",
       " 'tec_dist': {'decimals': None,\n",
       "  'parameters': [0.5, None],\n",
       "  'round': False,\n",
       "  'type': 'bernoulli'},\n",
       " 'tec_levels': tensor([0, 1])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parameter file using intrinsic set_model_parameters function:\n",
    "model = dgl_ptm.PovertyTrapModel(model_identifier='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_model_parameters(default=False, parameterFilePath='../dgl_ptm/dgl_ptm/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha_dist': {'decimals': None,\n",
       "  'parameters': [1.08, 0.074],\n",
       "  'round': False,\n",
       "  'type': 'normal'},\n",
       " 'capital_dist': {'decimals': None,\n",
       "  'parameters': [0.1, 10.0],\n",
       "  'round': False,\n",
       "  'type': 'uniform'},\n",
       " 'cost_vals': tensor([0.0000, 0.4500]),\n",
       " 'gamma_vals': tensor([0.3000, 0.4500]),\n",
       " 'initial_graph_type': 'barabasi-albert',\n",
       " 'lam_dist': {'decimals': 1,\n",
       "  'parameters': [0.1, 0.9],\n",
       "  'round': True,\n",
       "  'type': 'uniform'},\n",
       " 'number_agents': 1000,\n",
       " 'sigma': 0.5,\n",
       " 'steering_parameters': {'del_prob': 0.05,\n",
       "  'edata': ['all'],\n",
       "  'epath': './edge_data',\n",
       "  'mode': 'xarray',\n",
       "  'ndata': ['all'],\n",
       "  'npath': './agent_data.zarr',\n",
       "  'ratio': 0.1,\n",
       "  'wealth_method': 'weighted_transfer',\n",
       "  'weight_a': 0.69,\n",
       "  'weight_b': 35},\n",
       " 'step_count': 0,\n",
       " 'step_target': 20,\n",
       " 'tec_dist': {'decimals': None,\n",
       "  'parameters': [0.5, None],\n",
       "  'round': False,\n",
       "  'type': 'bernoulli'},\n",
       " 'tec_levels': tensor([0, 1])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl_ptm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
